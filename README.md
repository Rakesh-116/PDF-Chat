# ğŸ“š RAG Document-Based Chatbot

A powerful **Retrieval-Augmented Generation (RAG)** chatbot that allows users to upload PDF documents and ask intelligent questions about their content. Built with modern technologies for seamless document processing and conversational AI.

![RAG Chatbot](https://img.shields.io/badge/RAG-Chatbot-blue?style=for-the-badge)
![Next.js](https://img.shields.io/badge/Next.js-15.4.3-black?style=for-the-badge&logo=next.js)
![Express](https://img.shields.io/badge/Express-5.1.0-green?style=for-the-badge&logo=express)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?style=for-the-badge&logo=typescript)

## ğŸš€ Features

- **ğŸ“„ PDF Upload & Processing**: Upload PDF documents for intelligent analysis
- **ğŸ¤– AI-Powered Chat**: Ask questions and get accurate answers from your documents
- **ğŸ” Semantic Search**: Advanced vector-based document retrieval using Qdrant
- **ğŸ“š Document Chunking**: Smart text splitting for optimal context understanding
- **ğŸ¯ Source Citations**: See exactly which pages and documents your answers come from
- **âš¡ Real-time Processing**: Background job processing with Redis and BullMQ
- **ğŸ¨ Modern UI**: Clean, responsive interface built with Next.js and Tailwind CSS

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI   â”‚ -> â”‚  Express API    â”‚ -> â”‚   Vector DB     â”‚
â”‚   (Frontend)    â”‚    â”‚   (Backend)     â”‚    â”‚   (Qdrant)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Job Queue     â”‚
                       â”‚ (Redis+BullMQ)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Frontend

- **Next.js 15.4.3** - React framework with Turbopack
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first CSS framework
- **shadcn/ui** - Modern UI components
- **Clerk** - Authentication (optional)

### Backend

- **Express.js 5.1.0** - Web framework
- **Multer** - File upload handling
- **LangChain** - Document processing and AI orchestration
- **Qdrant** - Vector database for embeddings
- **Redis + BullMQ** - Job queue for background processing

### AI & ML

- **HuggingFace Transformers** - Text embeddings (all-MiniLM-L6-v2)
- **OpenAI Embeddings** - Alternative embedding model
- **PDF Loader** - Document parsing and text extraction

## ğŸ“¦ Installation

### Prerequisites

- Node.js 18+ and npm
- Redis server
- Qdrant vector database

### 1. Clone the Repository

```bash
git clone <repository-url>
cd "Document Based Chatbot"
```

### 2. Setup Backend

```bash
cd server
npm install

# Create environment file
echo "QDRANT_URL=http://localhost:6333" > .env
echo "OPENAI_API_KEY=your_openai_api_key" >> .env
```

### 3. Setup Frontend

```bash
cd ../client
npm install
```

### 4. Start Services

**Start Redis:**

```bash
# Windows (if using Redis on Windows)
redis-server

# MacOS/Linux
brew services start redis
# or
sudo systemctl start redis
```

**Start Qdrant:**

```bash
# Using Docker
docker run -p 6333:6333 qdrant/qdrant

# Or visit: http://localhost:6333/dashboard
```

### 5. Run the Application

**Backend:**

```bash
cd server
npm run dev
```

**Frontend:**

```bash
cd client
npm run dev
```

Visit `http://localhost:3000` to access the application!

## ğŸ¯ Usage

### 1. Upload Documents

- Navigate to the upload page
- Select PDF files to upload
- Files are automatically processed in the background

### 2. Chat with Your Documents

- Go to the chat interface
- Ask questions about your uploaded documents
- Get AI-powered answers with source citations

### Example Queries:

- "What are the main themes in this book?"
- "Summarize chapter 3"
- "What does the author say about habit formation?"

## ğŸ”§ Configuration

### Environment Variables

**Server (.env):**

```env
QDRANT_URL=http://localhost:6333
OPENAI_API_KEY=your_openai_api_key_here
REDIS_HOST=localhost
REDIS_PORT=6379
```

### Embedding Models

The project supports multiple embedding models:

```javascript
// HuggingFace (Local, Free)
const embeddings = new HuggingFaceTransformersEmbeddings({
  modelName: "Xenova/all-MiniLM-L6-v2",
});

// OpenAI (API-based, Paid)
const embeddings = new OpenAIEmbeddings({
  apiKey: process.env.OPENAI_API_KEY,
  model: "text-embedding-3-small",
});
```

## ğŸ“ Project Structure

```
Document Based Chatbot/
â”œâ”€â”€ client/                 # Next.js frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.tsx   # Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ file-upload.tsx
â”‚   â”‚   â”œâ”€â”€ globals.css    # Global styles
â”‚   â”‚   â”œâ”€â”€ layout.tsx     # App layout
â”‚   â”‚   â””â”€â”€ page.tsx       # Home page
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ server/                 # Express.js backend
â”‚   â”œâ”€â”€ uploads/           # Uploaded files storage
â”‚   â”œâ”€â”€ index.js          # Main server file
â”‚   â”œâ”€â”€ worker.js         # Background job processor
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”„ How It Works

1. **Document Upload**: User uploads PDF files via the frontend
2. **File Processing**: Multer saves files to `/uploads` directory
3. **Background Processing**: BullMQ queues the document for processing
4. **Text Extraction**: PDF content is extracted using LangChain's PDFLoader
5. **Text Chunking**: Documents are split into smaller, manageable chunks
6. **Embedding Generation**: Each chunk is converted to vector embeddings
7. **Vector Storage**: Embeddings are stored in Qdrant vector database
8. **Query Processing**: User questions are embedded and matched against stored vectors
9. **Response Generation**: Relevant chunks are retrieved and used to generate contextual answers

## ğŸ› Troubleshooting

### Common Issues

**1. "Collection doesn't exist" error:**

```javascript
// Use fromDocuments instead of fromExistingCollection
const vectorStore = await QdrantVectorStore.fromDocuments(
  texts,
  embeddings,
  config
);
```

**2. ES Module warnings:**
Add to server/package.json:

```json
{
  "type": "module"
}
```

**3. Redis connection issues:**

```bash
# Check if Redis is running
redis-cli ping
# Should return: PONG
```

**4. Qdrant connection issues:**

```bash
# Check Qdrant dashboard
curl http://localhost:6333/collections
```

## ğŸš€ Deployment

### Using Docker Compose

```yaml
version: "3.8"
services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"

  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"

  app:
    build: .
    ports:
      - "3000:3000"
      - "8000:8000"
    depends_on:
      - redis
      - qdrant
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) for document processing utilities
- [Qdrant](https://qdrant.tech/) for vector database capabilities
- [HuggingFace](https://huggingface.co/) for transformer models
- [shadcn/ui](https://ui.shadcn.com/) for beautiful UI components

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the [Troubleshooting](#-troubleshooting) section
2. Search existing [Issues](../../issues)
3. Create a new issue with detailed information

---

**Happy chatting with your documents! ğŸ“šğŸ¤–**
